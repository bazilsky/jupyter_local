{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6c1e654-f743-46e0-9737-57f27f314595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import iris\n",
    "import numpy as np \n",
    "import pylab as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import os\n",
    "import netCDF4 as nc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b1fc0fc-c725-4394-8fb9-414da8a499ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Regional gridded output from a Regional Climate Model (RCM)\n",
    "hi_t2   = xr.open_dataset('data/hifid_t2m_monthly.nc')\n",
    "hi_lats = hi_t2['latitude'].values\n",
    "hi_lons = hi_t2['longitude'].values \n",
    "\n",
    "### Global gridded reanalysis (data assimilated) used to update/force the \n",
    "### lateral boundaries of the RCM\n",
    "lo_t2  = xr.open_dataset('data/lofid_t2m_monthly.nc')\n",
    "lo_u10 = xr.open_dataset('data/lofid_u10_monthly.nc')\n",
    "lo_v10 = xr.open_dataset('data/lofid_v10_monthly.nc')\n",
    "\n",
    "### work with numpy arrays\n",
    "hi_t2_arr  = hi_t2['t2m'].values\n",
    "lo_t2_arr  = lo_t2['t2m'].values \n",
    "lo_u10_arr = lo_u10['u10'].values\n",
    "lo_v10_arr = lo_v10['v10'].values\n",
    "time_dim   = lo_t2['time'].values \n",
    "\n",
    "##low fidelity lat and lon \n",
    "lo_lats = lo_t2['latitude'].values\n",
    "lo_lons = lo_t2['longitude'].values\n",
    "\n",
    "# high fidelity elevation data \n",
    "hi_elev = xr.open_dataset('data/hifid_hgt.nc')['hgt'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3c78fb4-54a6-4101-acae-b60418e46b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_temp_model(temp_data, elevation_data, temp_data_lowres):\n",
    "    # Convert data to float32\n",
    "    temp_data = temp_data.astype(np.float32)\n",
    "    elevation_data = elevation_data.astype(np.float32)\n",
    "\n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(temp_data.shape[1],)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(elevation_data.shape[1]))\n",
    "    \n",
    "\n",
    "    # Compile the model\n",
    "    #model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    # Train the model\n",
    "    model.fit(temp_data, elevation_data, epochs=100, batch_size=32, verbose = False) # verbose = 0 showing no training progress\n",
    "    \n",
    "    old_shape = temp_data_lowres.shape\n",
    "    new_shape = temp_data.shape\n",
    "\n",
    "    padded_array = np.zeros(new_shape)\n",
    "    padded_array[:old_shape[0],:old_shape[1]] = temp_data_lowres\n",
    "    \n",
    "    elev_pred = model.predict(padded_array)\n",
    "    \n",
    "    elev_pred_slice = elev_pred[:old_shape[0],:old_shape[1]]\n",
    "    #model.evaluate(temp_data,elevation_data)\n",
    "    #print ('accuracy = ', accuracy)\n",
    "    return elev_pred_slice\n",
    "\n",
    "def save_netcdf(array):\n",
    "\n",
    "    filename = 'low_fidelity_elevation.nc'\n",
    "    filepath = os.path.join(os.getcwd(),filename)\n",
    "    flag = os.path.exists(filepath)\n",
    "    if flag == True:\n",
    "        os.remove(filename)\n",
    "    ds = nc.Dataset(filename,'w',format = 'NETCDF4')\n",
    "\n",
    "    time = ds.createDimension('time',array.shape[0])\n",
    "    lat_dim = ds.createDimension('latitude',array.shape[1])\n",
    "    lon_dim = ds.createDimension('longitude',array.shape[2])\n",
    "\n",
    "    temp_time = np.linspace(1,2,468)\n",
    "    temp_lat = lo_lats\n",
    "    temp_lon = lo_lons\n",
    "    #np.shape(temp_time)\n",
    "\n",
    "    times = ds.createVariable('time', 'f4', ('time',))\n",
    "    lats = ds.createVariable('latitude', 'f4', ('latitude',))\n",
    "    lons = ds.createVariable('longitude', 'f4', ('longitude',))\n",
    "    value = ds.createVariable('lo_elev', 'f4', ('time', 'latitude', 'longitude',))\n",
    "    value.units = 'm'\n",
    "\n",
    "    lats[:]=temp_lat\n",
    "    lons[:]=temp_lon\n",
    "    times[:]= temp_time\n",
    "\n",
    "    value[:,:,:] = array[:,:,:]\n",
    "    ds.close()\n",
    "\n",
    "    #cube111 = iris.load('snow_depth_1.nc')\n",
    "    #cube111\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16ab93f8-d83d-4786-a4c4-7a151a6fde8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value os i is 0 and max val = 468\n",
      "value os i is 1 and max val = 468\n",
      "(468, 93, 87)\n",
      "(468, 54, 52)\n",
      "(1, 54, 52)\n"
     ]
    }
   ],
   "source": [
    "temp = np.array([]) # this is an array that will store\n",
    "\n",
    "# these for loops are to generate temp array that will store the low fidelity elevation elevation profile\n",
    "\n",
    "for i in range(hi_t2_arr.shape[0]):\n",
    "#for i in range(2):\n",
    "    pred = train_temp_model(hi_t2_arr[i,:,:], hi_elev, lo_t2_arr[i,:,:])\n",
    "    pred = pred[np.newaxis,:,:] # add a new axis\n",
    "    if i ==0:\n",
    "        temp = pred.copy()\n",
    "    else:\n",
    "        temp = np.concatenate([temp,pred], axis = 0)\n",
    "    print(f'value os i is {i} and max val = {hi_t2_arr.shape[0]}')\n",
    "lo_elev = temp\n",
    "print(hi_t2_arr.shape)\n",
    "print(lo_t2_arr.shape)\n",
    "print(pred.shape)\n",
    "\n",
    "#save_netcdf(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da87c502-cb96-45e7-b007-68e38a5f0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_netcdf(filename, time, latitude, longitude, data):\n",
    "    \n",
    "    #filename = 'low_fidelity_elevation.nc'\n",
    "    filepath = os.path.join(os.getcwd(),filename)\n",
    "    flag = os.path.exists(filepath)\n",
    "    \n",
    "    if flag == True:\n",
    "        os.remove(filename)\n",
    "    \n",
    "    # Open a new NetCDF file\n",
    "    nc_file = nc.Dataset(filename, \"w\", format=\"NETCDF4\")\n",
    "\n",
    "    # Create dimensions\n",
    "    nc_file.createDimension(\"time\", len(time))\n",
    "    nc_file.createDimension(\"latitude\", len(latitude))\n",
    "    nc_file.createDimension(\"longitude\", len(longitude))\n",
    "\n",
    "    # Create variables\n",
    "    time_var = nc_file.createVariable(\"time\", \"f8\", (\"time\",))\n",
    "    lat_var = nc_file.createVariable(\"latitude\", \"f4\", (\"latitude\",))\n",
    "    lon_var = nc_file.createVariable(\"longitude\", \"f4\", (\"longitude\",))\n",
    "    data_var = nc_file.createVariable(\"lo_elev\", \"f4\", (\"time\", \"latitude\", \"longitude\"))\n",
    "\n",
    "    # Write data to variables\n",
    "    time_var[:] = time\n",
    "    lat_var[:] = latitude\n",
    "    lon_var[:] = longitude\n",
    "    data_var[:] = data\n",
    "\n",
    "    # Add variable attributes\n",
    "    #time_var.units = \"hours since 0001-01-01 00:00:00\"\n",
    "    lat_var.units = \"degrees\"\n",
    "    lon_var.units = \"degrees\"\n",
    "\n",
    "    # Close the NetCDF file\n",
    "    nc_file.close()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "time = time_dim\n",
    "latitude = lo_lats\n",
    "longitude = lo_lons\n",
    "data = pred\n",
    "create_netcdf(\"low_fidelity_elevation.nc\", time, latitude, longitude, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc662301-186a-4786-9d3e-c7607f79e28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 54, 52)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!jupyter nbconvert --to script downscale_padding.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b534c-f034-4682-86ad-7b040431a162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "361e4bc2-f91b-487d-a8f0-b4562d6eab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import iris\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature\n",
    "from datetime import datetime,timedelta\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e419d6c-7492-45ec-8313-c8afd66c7d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ananth/miniconda3/envs/tensorflow_env/lib/python3.7/site-packages/iris/fileformats/cf.py:649: UserWarning: Missing CF-netCDF grid mapping variable 'lambert_azimuthal_equal_area', referenced by netCDF variable 'snod'\n",
      "  warnings.warn(message % (name, nc_var_name))\n"
     ]
    }
   ],
   "source": [
    "#filename = '/Users/ananth/Downloads/SM_sden_ERA5_01Aug1980-31Jul2021_v01.nc'\n",
    "#cube = iris.load(filename)\n",
    "\n",
    "filename = '/Users/ananth/Downloads/SM_snod_ERA5_01Aug1980-31Jul2021_v01.nc'\n",
    "cube = iris.load(filename)\n",
    "\n",
    "lat_index = 0\n",
    "lon_index = 0\n",
    "snowdepth_index = 0\n",
    "\n",
    "for i in range(2):\n",
    "    varname = cube[i].var_name\n",
    "    if varname == 'snod':\n",
    "        snowdepth_index = i\n",
    "\n",
    "snow_depth_org = cube[snowdepth_index].data\n",
    "snow_depth_org[snow_depth_org<0] = 0\n",
    "filename4 = '/Users/ananth/Downloads/icemotion_weekly_nh_25km_19781105_19781231_v4.1.nc'\n",
    "cube4 = iris.load(filename4)\n",
    "\n",
    "lat_index = 0\n",
    "lon_index = 0\n",
    "\n",
    "for i in range(5):\n",
    "    varname = cube4[i].var_name\n",
    "    if varname == 'latitude':\n",
    "        lat_index = i\n",
    "    elif varname == 'longitude':\n",
    "        lon_index = i\n",
    "        \n",
    "lon = cube4[lon_index].data\n",
    "lat = cube4[lat_index].data\n",
    "\n",
    "snow_depth = snow_depth_org[-365:,:,:].data # this is for the one year .. slice \n",
    "\n",
    "snow_depth_1yr = snow_depth_org[-30:,:,:].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5698e12d-d5c6-4b46-a9a5-e0420eefacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_cube = cube[snowdepth_index]\n",
    "time_arr = depth_cube.coord('time').points\n",
    "np.shape(time_arr)\n",
    "\n",
    "start_date = '08/01/1980'\n",
    "date_1 = datetime.strptime(start_date,'%m/%d/%Y').date()\n",
    "date_arr =[start_date]\n",
    "#new_date = []\n",
    "new_date = 0\n",
    "\n",
    "for i in range(len(time_arr)-1):\n",
    "    new_date = date_1+timedelta(days = i)\n",
    "    new_date_str = new_date.strftime('%m/%d/%Y')\n",
    "    date_arr += [new_date_str]\n",
    "    #print(date_arr)\n",
    "\n",
    "index_1 = date_arr.index('01/01/2020')\n",
    "index_2 = date_arr.index('12/31/2020')\n",
    "#date_arr[index_1:index_2+1]\n",
    "\n",
    "snow_depth_1yr_slice = snow_depth_org[index_1:index_2+1,:,:].data\n",
    "\n",
    "start_date_2 = datetime.strptime('01/01/2020','%m/%d/%Y').date()\n",
    "\n",
    "snow_depth_annual = np.zeros((12,361,361))\n",
    "\n",
    "for i in range(12):\n",
    "    \n",
    "    new_date_2 = start_date_2+relativedelta(months= i) \n",
    "    new_date_2_str = new_date_2.strftime('%m/%d/%Y')\n",
    "    index_2 = date_arr.index(new_date_2_str)\n",
    "    snow_depth_1month = snow_depth_org[index_1:index_2+1,:,:]\n",
    "    snow_depth_1month_mean = np.mean(snow_depth_1month,axis=0)\n",
    "    snow_depth_annual[i,:,:] = snow_depth_1month_mean.data\n",
    "    \n",
    "    print(index_1,index_2)\n",
    "    index_1 = index_2\n",
    "    print(date_arr[index_2])\n",
    "    \n",
    "print(np.shape(snow_depth_annual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781bd7a3-3801-49ce-8944-cffabdfd4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(snow_depth_1yr_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72e8d3-4aaa-47f6-8505-9a29707ff0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert snow_depth_annual from 12,361,361 array to 12,722,722\n",
    "\n",
    "lat_org = np.sort(lat.flatten())\n",
    "lon_org = np.sort(lon.flatten())\n",
    "\n",
    "\n",
    "lat_1d = lat.flatten()\n",
    "lon_1d = lon.flatten()\n",
    "\n",
    "lat_sort_index = np.argsort(lat_1d)\n",
    "lon_sort_index = np.argsort(lon_1d)\n",
    "\n",
    "\n",
    "\n",
    "lat_lon = np.zeros((722,722))\n",
    "\n",
    "new_SD = np.zeros((12,722,722))\n",
    "\n",
    "for i in range(722):\n",
    "    index1 = np.where(lat_sort_index == i)\n",
    "    index2 = np.where(lon_sort_index == i)\n",
    "    \n",
    "    new_SD[0,index1,index2] = snow_depth_annual[0,] \n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for i in range(len(lat_org)):\n",
    "    index1 = np.where(lat_1d[i]==lat_org)\n",
    "    index2 = np.where(lon_1d[index_1] == lon_org)\n",
    "    for j in range(len(index1)):\n",
    "        new_SD[0,j,index2]\n",
    "        \n",
    "        for j in range(len(lon_org)):\n",
    "            index3 = np.where(lon)\n",
    "        \n",
    "\n",
    "np.shape(snow_depth_annual)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "a = np.array([1,2,3,4,5,0])\n",
    "b= np.array([12,1,14,3,7,0])\n",
    "print(np.argsort(a))\n",
    "print(np.argsort(b))\n",
    "\n",
    "np.where(lat_sort_index==1)\n",
    "lat_sort_index[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5618711-2332-4ad5-8c61-d142a57fbe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save snow depth, latitude and longitude into a netcdf file\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "\n",
    "fn = 'snow_depth_1.nc'\n",
    "\n",
    "os.remove(fn)\n",
    "ds = nc.Dataset(fn,'w',format = 'NETCDF4')\n",
    "\n",
    "time = ds.createDimension('time',12)\n",
    "lat_dim = ds.createDimension('unknown1',361)\n",
    "lon_dim = ds.createDimension('unknown2',361)\n",
    "\n",
    "temp_time = np.arange(1,13,1)\n",
    "temp_lat = np.linspace(1,2,361)\n",
    "temp_lon = np.linspace(1,2,361)\n",
    "np.shape(temp_time)\n",
    "\n",
    "times = ds.createVariable('time', 'f4', ('time',))\n",
    "lats = ds.createVariable('unknown1', 'f4', ('unknown1',))\n",
    "lons = ds.createVariable('unknown2', 'f4', ('unknown2',))\n",
    "value = ds.createVariable('snow_depth', 'f4', ('time', 'unknown1', 'unknown2',))\n",
    "value.units = 'm'\n",
    "\n",
    "lats[:]=temp_lat\n",
    "lons[:]=temp_lon\n",
    "times[:]= temp_time\n",
    "\n",
    "value[:,:,:] = snow_depth_annual\n",
    "ds.close()\n",
    "\n",
    "cube111 = iris.load('snow_depth_1.nc')\n",
    "cube111\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d591c9b-a5f6-4095-8e48-62f2d735a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save latitude into a cube\n",
    "\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "\n",
    "fn = 'latitude.nc'\n",
    "\n",
    "os.remove(fn)\n",
    "ds = nc.Dataset(fn,'w',format = 'NETCDF4')\n",
    "\n",
    "#time = ds.createDimension('time',12)\n",
    "lat_dim = ds.createDimension('unknown1',361)\n",
    "lon_dim = ds.createDimension('unknown2',361)\n",
    "\n",
    "#temp_time = np.arange(1,13,1)\n",
    "temp_lat = np.linspace(1,2,361)\n",
    "temp_lon = np.linspace(1,2,361)\n",
    "#np.shape(temp_time)\n",
    "\n",
    "#times = ds.createVariable('time', 'f4', ('time',))\n",
    "lats = ds.createVariable('unknown1', 'f4', ('unknown1',))\n",
    "lons = ds.createVariable('unknown2', 'f4', ('unknown2',))\n",
    "value = ds.createVariable('latitude', 'f4', ('unknown1', 'unknown2',))\n",
    "value.units = 'm'\n",
    "\n",
    "lats[:]=temp_lat\n",
    "lons[:]=temp_lon\n",
    "#times[:]= temp_time\n",
    "\n",
    "value[:,:] = lat\n",
    "ds.close()\n",
    "\n",
    "cube111 = iris.load('latitude.nc')\n",
    "cube111\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2775b57-5675-4422-bdd3-0e4870cf955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save longitude array into a cube\n",
    "\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "\n",
    "fn = 'longitude.nc'\n",
    "\n",
    "#os.remove(fn)\n",
    "ds = nc.Dataset(fn,'w',format = 'NETCDF4')\n",
    "\n",
    "#time = ds.createDimension('time',12)\n",
    "lat_dim = ds.createDimension('unknown1',361)\n",
    "lon_dim = ds.createDimension('unknown2',361)\n",
    "\n",
    "#temp_time = np.arange(1,13,1)\n",
    "temp_lat = np.linspace(1,2,361)\n",
    "temp_lon = np.linspace(1,2,361)\n",
    "#np.shape(temp_time)\n",
    "\n",
    "#times = ds.createVariable('time', 'f4', ('time',))\n",
    "lats = ds.createVariable('unknown1', 'f4', ('unknown1',))\n",
    "lons = ds.createVariable('unknown2', 'f4', ('unknown2',))\n",
    "value = ds.createVariable('longitude', 'f4', ('unknown1', 'unknown2',))\n",
    "value.units = 'm'\n",
    "\n",
    "lats[:]=temp_lat\n",
    "lons[:]=temp_lon\n",
    "#times[:]= temp_time\n",
    "\n",
    "value[:,:] = lon\n",
    "ds.close()\n",
    "\n",
    "cube111 = iris.load('longitude.nc')\n",
    "cube111\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a32df6e-706e-4a43-a155-3691fdefffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_depth_1yr = snow_depth_org[-730:-365,:,:].data\n",
    "snow_depth_1yr[snow_depth_1yr<0] = 0\n",
    "snow_depth = np.mean(snow_depth_1yr,axis=0)\n",
    "np.max(snow_depth)\n",
    "\n",
    "#np.max(snow_depth_annual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a7d3e-1568-4f1c-952c-018edb32d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,8),  subplot_kw={'projection': ccrs.NorthPolarStereo()})\n",
    "\n",
    "ax.add_feature(cartopy.feature.LAND, edgecolor='black',zorder=1)\n",
    "#ax.add_feature(cartopy.feature.OCEAN)\n",
    "\n",
    "lat_1d = lat.flatten();\n",
    "lon_1d = lon.flatten();\n",
    "\n",
    "snowdepth_1d = snow_depth.flatten()*100\n",
    "\n",
    "#j = np.isnan(snowdepth_1d)\n",
    "#s_depth_slice = snowdepth_1d[~j]\n",
    "#lat_slice = lat_1d[~j]\n",
    "#lon_slice = lon_1d[~j]\n",
    "\n",
    "#colors = snowdepth_1d/np.max(snowdepth_1d_depth_slice)\n",
    "\n",
    "colors = snowdepth_1d\n",
    "\n",
    "im = ax.scatter(lon_1d, lat_1d,c = colors,s = 100, marker = '.',transform = ccrs.PlateCarree(),zorder = 5)\n",
    "cb = fig.colorbar(im,ax=ax,fraction=0.046, pad=0.04)\n",
    "ax.set_extent([-180, 180, 90, 60], ccrs.PlateCarree())\n",
    "cb.ax.tick_params(labelsize=18)\n",
    "plt.title('Snow depth (cm) (SnowModel LG data)',fontsize = 24)\n",
    "ax.gridlines()\n",
    "\n",
    "\"\"\"         \n",
    "#ax.scatter(lat[])\n",
    "#ax.colorbar()\n",
    "ax.set_title('Snow depth in the Arctic (cm)',fontsize=25)\n",
    "cb.ax.tick_params(labelsize=18)\n",
    "#ax.legend(fontsize='x-large')\n",
    "ax.gridlines()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7d431-5f9c-42d2-bda8-6907a5061040",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(snow_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad531d29-f2a1-4afd-9e5f-5a611b849ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3 = '/Users/ananth/Downloads/SM_sden_MERRA2_01Aug1980-31Jul2021_v01.nc'\n",
    "cube3 = iris.load(filename3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfee49f-5595-422b-8c75-a096636e6c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename4 = '/Users/ananth/Downloads/icemotion_weekly_nh_25km_19781105_19781231_v4.1.nc'\n",
    "cube4 = iris.load(filename4)\n",
    "cube4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76523ebe-9b53-4299-ad37-78a522283de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_date = '08-01-1980'\n",
    "#date_1 = datetime.strptime(start_date,'%m-%d-%Y').date()\n",
    "\n",
    "start_date = '08/01/1980'\n",
    "date_1 = datetime.strptime(start_date,'%m/%d/%Y').date()\n",
    "#x = datetime.datetime.strptime('08/01/1980','%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc51008-4726-4883-88f6-89c31944fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "\n",
    "datetime_str = '09/19/22'\n",
    "\n",
    "datetime_object = datetime.strptime(datetime_str, '%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d88fa42-28eb-43f0-b3e2-6a56a561ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_1 = date_arr.index('01/01/2020')\n",
    "index_2 = date_arr.index('12/31/2020')\n",
    "date_arr[index_1:index_2+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c12648-1ba7-424f-8fbf-b4c89ce5f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tomcat lat and lon\n",
    "\n",
    "tomcat_lat = [87.86, 85.10, 82.31, 79.53, 76.74,\n",
    "        73.95, 71.16, 68.37, 65.58, 62.79,\n",
    "        60.00, 57.21, 54.42, 51.63, 48.84,\n",
    "        46.04, 43.25, 40.46, 37.67, 34.88,\n",
    "        32.09, 29.30, 26.51, 23.72, 20.93,\n",
    "        18.14, 15.35, 12.56,  9.77,  6.98,\n",
    "         4.19,  1.40, -1.40, -4.19, -6.98,\n",
    "        -9.77,-12.56,-15.35,-18.14,-20.93,\n",
    "       -23.72,-26.51,-29.30,-32.09,-34.88,\n",
    "       -37.67,-40.46,-43.25,-46.04,-48.84,\n",
    "       -51.63,-54.42,-57.21,-60.00,-62.79,\n",
    "       -65.58,-68.37,-71.16,-73.95,-76.74,\n",
    "       -79.53,-82.31,-85.10,-87.86]\n",
    "\n",
    "tomcat_lon_360 = np.arange(0,360,2.8125)\n",
    "\n",
    "tomcat_lon = []\n",
    "new_lon = 0\n",
    "\n",
    "for i in range(len(tomcat_lon_360)):\n",
    "    if tomcat_lon_360[i] > 180:\n",
    "        new_lon = tomcat_lon_360[i]-360\n",
    "    else:\n",
    "        new_lon = tomcat_lon_360[i]\n",
    "    tomcat_lon = np.append(tomcat_lon,new_lon)\n",
    "    \n",
    "tomcat_lon = np.sort(tomcat_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd46fe1-4243-4c8d-96ac-4ce826b39872",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min and max lat = ', np.min(lat_1d),np.max(lat_1d))\n",
    "print('min and max lon = ', np.min(lon_1d),np.max(lon_1d))\n",
    "X,Y = np.meshgrid (lon_1d,lat_1d)\n",
    "for i in range(len(tomcat_lat)):\n",
    "    for j in range(len(tomcat_lon)):\n",
    "        flag = (tomcat_lat[i]>np.min(lat_1d) and tomcat_lat[i]<np.max(lat_1d) and tomcat_lon[j]>np.min(lon_1d) and tomcat_lon[j]<np.max(lon_1d))\n",
    "        if flag == True:\n",
    "            print(flag)\n",
    "            lat_point = tomcat_lat[i]\n",
    "            lon_point = tomcat_lon[j]\n",
    "            data = snow_depth_annual[0,:,:]\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d052e-345f-4c79-827d-548988187787",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_depth_annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d40fbb-3447-452d-8575-06ab784d3fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6271b-7c56-4542-8b9b-0ba491a4b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([12,12,13,4,5,6])\n",
    "np.where(a==4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1735e920-38c1-4c19-9df6-d99ab777a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_org = np.sort(lat.flatten())\n",
    "lon_org = np.sort(lon.flatten())\n",
    "\n",
    "lat_1d = lat.flatten();\n",
    "lon_1d = lon.flatten();\n",
    "\n",
    "np.where(lat_org[10]==lat_1d)\n",
    "\n",
    "#lat_org[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676daffc-4b7f-4a7b-a9dc-64c4147322c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_org[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a48cf-eedd-4c22-9e5f-611d444b1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_org[360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216936fc-972d-4869-8861-ff493178f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_1d[360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6f796-2fe5-4a11-9340-9379b949c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(361):\n",
    "    print('lon_original index = ', i)\n",
    "    for j in range(361):\n",
    "        if j!=i:\n",
    "            flag = (lon[i,:] - lon[j,:] == 0)\n",
    "    #print('value of flag = ', flag)\n",
    "    #print('shape of flag = ', np.shape(flag))\n",
    "            if flag.all() == True:\n",
    "            #print('hello')\n",
    "                print ('same data at other indices = ', j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73b6d5-bd2d-4c87-be7c-cb8c800e8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(361):\n",
    "    print('lat_original index = ', i)\n",
    "    for j in range(361):\n",
    "        if j!=i:\n",
    "            flag = (lat[i,:] - lat[j,:] == 0)\n",
    "    #print('value of flag = ', flag)\n",
    "    #print('shape of flag = ', np.shape(flag))\n",
    "            if flag.all() == True:\n",
    "            #print('hello')\n",
    "                print ('same data at other indices = ', j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421cf06-585f-4d65-9a99-75e566433b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705f992-1c21-4b22-8f28-4540355b4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_1d = lat.flatten();\n",
    "lon_1d = lon.flatten();\n",
    "\n",
    "snowdepth_1d = snow_depth.flatten()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5aabc1-dec4-4387-a605-91c86c4ac4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowdepth_1d.reshape((12,361,361))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f314bb0-f59a-47ec-b621-eb2b1d9156d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(snow_depth_annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31597122-8ad8-4428-8c1e-51fd833d7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "temp_lon = np.linspace(1,2,361)\n",
    "temp_lon.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ff208-c5dd-4341-b9bf-807974485ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
